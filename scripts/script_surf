#!/bin/bash
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
<<<<<<< HEAD
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 4-23:59:00
#SBATCH --cpus-per-task=30
=======
#SBATCH --gpus-per-node=4
#SBATCH --gpus=3
#SBATCH -t 4-23:59:00
#SBATCH --cpus-per-task=40
>>>>>>> c756c598179dbb584c08f048ab8e23c38e33e2fc
#SBATCH --exclusive
#SBATCH -o address.out

source /home/shiweil/miniconda3/etc/profile.d/conda.sh
source activate pt1.10_cuda11.3

module purge
module load 2021
module load CUDA/11.3.1
#module load PyTorch/1.10.0-foss-2021a-CUDA-11.3.1


MODEL=van_tiny # van_{tiny, small, base, large}
DROP_PATH=0.1 # drop path rates [0.1, 0.1, 0.1, 0.2] for [tiny, small, base, large]
<<<<<<< HEAD
CUDA_VISIBLE_DEVICES=0 bash distributed_train.sh 1 /scratch-shared/shiwei/ \
	  --sparse --model $MODEL -b 64 --lr 1e-3 --drop-path $DROP_PATH --
=======
CUDA_VISIBLE_DEVICES=0,1,2 bash distributed_train.sh 3 /scratch-shared/shiwei/ \
	  --sparse --model $MODEL -b 128 --lr 1e-3 --drop-path $DROP_PATH
>>>>>>> c756c598179dbb584c08f048ab8e23c38e33e2fc


source deactivate
